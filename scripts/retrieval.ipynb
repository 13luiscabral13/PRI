{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_NUMBER = \"q4\"\n",
    "QUERY_PATH = '../queries/' + QUERY_NUMBER + '/' + QUERY_NUMBER\n",
    "\n",
    "BASE_QUERY_URL = \"http://localhost:8983/solr/games/select?fl=*%2C%5Bchild%5D&fq=%7B!child%20of%3D%22*%3A*%20-_nest_path_%3A*%22%7Dsummary%3A(unique%20OR%20characters%20OR%20%22unique%20story%22)%20OR%20wikipedia%3A(unique%20OR%20characters%20OR%20%22unique%20story%22)&indent=true&q.op=OR&q=review%3A(unique%20OR%20characters%20OR%20%22unique%20story%22)&rows=1000&useParams=&wt=json\"\n",
    "BOOSTED_QUERY_URL = \"http://localhost:8983/solr/games/select?bq=platform%3A%22Playstation%204%22%5E3%20summary%3A%22basketball%22%5E4&defType=edismax&fl=*%2C%5Bchild%5D&fq=%7B!child%20of%3D%22*%3A*%20-_nest_path_%3A*%22%7Dtitle%3Abasketball%20OR%20summary%3A(basketball%20OR%20best)%20%20OR%20wikipedia%3A(basketball%20OR%20best)%20OR%20genre%3Abasketball&indent=true&q.op=OR&q=review%3A(basketball%20OR%20best)%20platform%3A%22Playstation%204%22&useParams=&wt=json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Executa a base query e guarda os documentos obtidos no ficheiro baseRank.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8983/solr/games/select?fl=*%2C%5Bchild%5D&indent=true&q.op=OR&q=id%3A(cebab115-524b-4314-80bf-c0480a7780a8%20OR%209a569839-33a1-4633-8a38-91fda8ae64d0%20OR%20cebab115-524b-4314-80bf-c0480a7780a8%20OR%202a56005d-c01d-4927-a11e-9f468e80518e%20OR%20cebab115-524b-4314-80bf-c0480a7780a8%20OR%202a56005d-c01d-4927-a11e-9f468e80518e%20OR%209a569839-33a1-4633-8a38-91fda8ae64d0%20OR%205dc60e12-8268-48e8-8d77-d6074950b23f%20OR%20138a6a9b-a2fa-47c7-ad86-289e997167ac%20OR%202a56005d-c01d-4927-a11e-9f468e80518e)&useParams=&wt=json\n"
     ]
    }
   ],
   "source": [
    "#Query retorna reviews\n",
    "base_results = requests.get(BASE_QUERY_URL).json()['response']['docs']\n",
    "base_gameids = []\n",
    "\n",
    "for index, doc in enumerate(base_results):\n",
    "    if len(base_gameids) == 10:\n",
    "        break\n",
    "    \n",
    "    if doc['id'] not in base_gameids:\n",
    "        base_gameids.append(doc['id'].split('/')[0])\n",
    "\n",
    "id_string = 'id%3A(' + '%20OR%20'.join(map(str, base_gameids)) + ')&useParams=&wt=json'\n",
    "BASE_QUERY_URL = \"http://localhost:8983/solr/games/select?fl=*%2C%5Bchild%5D&indent=true&q.op=OR&q=\" + id_string\n",
    "\n",
    "print(BASE_QUERY_URL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8983/solr/games/select?fl=*%2C%5Bchild%5D&indent=true&q.op=OR&q=id%3A(cebab115-524b-4314-80bf-c0480a7780a8%20OR%209a569839-33a1-4633-8a38-91fda8ae64d0%20OR%20cebab115-524b-4314-80bf-c0480a7780a8%20OR%20cebab115-524b-4314-80bf-c0480a7780a8%20OR%209a569839-33a1-4633-8a38-91fda8ae64d0%20OR%20138a6a9b-a2fa-47c7-ad86-289e997167ac%20OR%2089d4576f-3609-41ee-9afb-92b2c637868c%20OR%20cebab115-524b-4314-80bf-c0480a7780a8%20OR%20cebab115-524b-4314-80bf-c0480a7780a8%20OR%20cebab115-524b-4314-80bf-c0480a7780a8)&useParams=&wt=json\n"
     ]
    }
   ],
   "source": [
    "#Query retorna reviews\n",
    "boosted_results = requests.get(BOOSTED_QUERY_URL).json()['response']['docs']\n",
    "boosted_gameids = []\n",
    "\n",
    "for index, doc in enumerate(boosted_results):\n",
    "    if len(boosted_gameids) == 10:\n",
    "        break\n",
    "    \n",
    "    if doc['id'] not in boosted_gameids:\n",
    "        boosted_gameids.append(doc['id'].split('/')[0])\n",
    "\n",
    "id_string = 'id%3A(' + '%20OR%20'.join(map(str, boosted_gameids)) + ')&useParams=&wt=json'\n",
    "BOOSTED_QUERY_URL = \"http://localhost:8983/solr/games/select?fl=*%2C%5Bchild%5D&indent=true&q.op=OR&q=\" + id_string\n",
    "\n",
    "print(BOOSTED_QUERY_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          BASE\n",
      "0      NBA 2K3\n",
      "1     NBA 2K16\n",
      "2  NBA Live 19\n",
      "3  NBA Live 15\n",
      "4       NBA 07\n"
     ]
    }
   ],
   "source": [
    "base_results = requests.get(BASE_QUERY_URL).json()['response']['docs']\n",
    "base_ranked_doc = [doc['title'] for index, doc in enumerate(base_results)]\n",
    "df_base = pd.DataFrame(base_ranked_doc, columns=['BASE'], index=None)\n",
    "\n",
    "print(df_base)\n",
    "\n",
    "latex_table = df_base.to_latex(index=False)\n",
    "\n",
    "with open(QUERY_PATH+'_baseRank.txt', 'w') as tf:\n",
    "    tf.write(latex_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Executa a boosted query e guarda os documentos obtidos no ficheiro boostedRank.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       BOOSTED\n",
      "0     NBA 2K16\n",
      "1  NBA Live 19\n",
      "2  NBA Live 16\n",
      "3  NBA Live 15\n"
     ]
    }
   ],
   "source": [
    "boosted_results = requests.get(BOOSTED_QUERY_URL).json()['response']['docs']\n",
    "boosted_ranked_doc = [doc['title'] for index, doc in enumerate(boosted_results)]\n",
    "\n",
    "df_boosted = pd.DataFrame(boosted_ranked_doc, columns=['BOOSTED'], index=None)\n",
    "\n",
    "print(df_boosted)\n",
    "\n",
    "latex_table = df_boosted.to_latex(index=False)\n",
    "\n",
    "with open(QUERY_PATH+'_boostedRank.txt', 'w') as tf:\n",
    "    tf.write(latex_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Depois construir o ficheiro com todos os documentos relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant = list(map(lambda el: el.strip(), open(QUERY_PATH+'_relevant.txt').readlines()))\n",
    "\n",
    "print(relevant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definição das métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {}\n",
    "metric = lambda f: metrics.setdefault(f.__name__, f)\n",
    "\n",
    "@metric\n",
    "def p10(results, relevant, n=10):\n",
    "    \"\"\"Precision at N\"\"\"\n",
    "    return len([doc for doc in results[:n] if doc['id'] in relevant])/n\n",
    "\n",
    "@metric\n",
    "def ap(results, relevant):\n",
    "    \"\"\"Average Precision\"\"\"\n",
    "    precision_values = []\n",
    "    relevant_count = 0\n",
    "\n",
    "    for idx, doc in enumerate(results):\n",
    "        if doc['id'] in relevant:\n",
    "            relevant_count += 1\n",
    "            precision_at_k = relevant_count / (idx + 1)\n",
    "            precision_values.append(precision_at_k)\n",
    "\n",
    "    if not precision_values:\n",
    "        return 0.0\n",
    "\n",
    "    return sum(precision_values)/len(precision_values)\n",
    "\n",
    "def calculate_metric(key, results, relevant):\n",
    "    return metrics[key](results, relevant)\n",
    "\n",
    "evaluation_metrics = {\n",
    "    'ap': 'Average Precision',\n",
    "    'p10': 'Precision at 10 (P@10)'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Função que cálcula a curva de Precision-Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(results, queryType):\n",
    "    precision_values = [\n",
    "        len([\n",
    "            doc \n",
    "            for doc in results[:idx]\n",
    "            if doc['id'] in relevant\n",
    "        ]) / idx \n",
    "        for idx, _ in enumerate(results, start=1)\n",
    "    ]\n",
    "    \n",
    "    recall_values = [\n",
    "        len([\n",
    "            doc for doc in results[:idx]\n",
    "            if doc['id'] in relevant\n",
    "        ]) / len(relevant)\n",
    "        for idx, _ in enumerate(results, start=1)\n",
    "    ]\n",
    "    \n",
    "    precision_recall_match = {k: v for k,v in zip(recall_values, precision_values)}\n",
    "    \n",
    "    # Extend recall_values to include traditional steps for a better curve (0.1, 0.2 ...)\n",
    "    recall_values.extend([step for step in np.arange(0.1, 1.1, 0.1) if step not in recall_values])\n",
    "    recall_values = sorted(set(recall_values))\n",
    "\n",
    "    # Extend matching dict to include these new intermediate steps\n",
    "    for idx, step in enumerate(recall_values):\n",
    "        if step not in precision_recall_match:\n",
    "            if recall_values[idx-1] in precision_recall_match:\n",
    "                precision_recall_match[step] = precision_recall_match[recall_values[idx-1]]\n",
    "            else:\n",
    "                precision_recall_match[step] = precision_recall_match[recall_values[idx+1]]\n",
    "\n",
    "    disp = PrecisionRecallDisplay([precision_recall_match.get(r) for r in recall_values], recall_values)\n",
    "    disp.plot()\n",
    "    plt.savefig(QUERY_PATH+'_'+queryType+'_pr.pdf')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cálculo da curva para a base query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(base_results, 'base')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cálculo da curva para a boosted query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(boosted_results, 'boosted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_document_ids = [doc['id'] for doc in base_results]\n",
    "base_relevance_column = ['Y' if doc_id in relevant else 'N' for doc_id in base_document_ids]\n",
    "\n",
    "boosted_document_ids = [doc['id'] for doc in boosted_results]\n",
    "boosted_relevance_column = ['Y' if doc_id in relevant else 'N' for doc_id in boosted_document_ids]\n",
    "\n",
    "ranked_documents = list(zip(range(1, len(base_results) + 1), base_document_ids, base_relevance_column, boosted_document_ids, boosted_relevance_column))\n",
    "\n",
    "df1 = pd.DataFrame(ranked_documents, columns=[('Rank', ''), ('Base System', 'Game'), ('Base System', 'Relevance'), ('Boosted System', 'Game'), ('Boosted System', 'Relevance')])\n",
    "\n",
    "# Convert the DataFrame to a LaTeX table without an index\n",
    "latex_table = df1.to_latex(index=False)\n",
    "\n",
    "# Write the LaTeX table to a file\n",
    "with open(QUERY_PATH+'_ranked_documents.tex', 'w') as tf:\n",
    "    tf.write(latex_table)\n",
    "\n",
    "# Print the LaTeX table\n",
    "print(latex_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
